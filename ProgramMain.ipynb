{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25186efd",
   "metadata": {
    "id": "25186efd"
   },
   "source": [
    "Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5228cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import os\n",
    "import io\n",
    "import base64\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# Data Processing & Math\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Audio Processing\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Web Framework\n",
    "from flask import Flask, render_template_string, render_template, request\n",
    "from werkzeug.utils import secure_filename\n",
    "\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from pyngrok import ngrok\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('token.env')  # Load dari file .env\n",
    "ngrok.set_auth_token(os.getenv(\"NGROK_AUTHTOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c36418",
   "metadata": {},
   "source": [
    "Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc525b8d",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286153,
     "status": "ok",
     "timestamp": 1746034606979,
     "user": {
      "displayName": "john alpha",
      "userId": "11702152668833067099"
     },
     "user_tz": -420
    },
    "id": "bc525b8d",
    "outputId": "e1aef29c-e9fc-42cc-fa91-3a85a4a13860"
   },
   "outputs": [],
   "source": [
    "# Fungsi ekstrak fitur MFCC dengan padding yang konsisten\n",
    "def extract_features(file_path, max_pad_len=500):  # Diperbesar menjadi 500\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_path, sr=22050, res_type='kaiser_fast')  # SR diset 22050 untuk konsistensi\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "\n",
    "        # Padding atau truncate ke max_pad_len\n",
    "        if mfccs.shape[1] > max_pad_len:\n",
    "            mfccs = mfccs[:, :max_pad_len]\n",
    "        else:\n",
    "            pad_width = max_pad_len - mfccs.shape[1]\n",
    "            mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "\n",
    "        return mfccs\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Muat dataset dengan penanganan error yang lebih baik\n",
    "def load_dataset(data_dir):\n",
    "    features = []\n",
    "    labels = []\n",
    "    label_dict = {}\n",
    "\n",
    "    # Cek semua kelas suara\n",
    "    class_names = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n",
    "\n",
    "    for label_idx, class_name in enumerate(class_names):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        label_dict[label_idx] = class_name\n",
    "\n",
    "        for file_name in os.listdir(class_dir):\n",
    "            if not file_name.lower().endswith(('.wav', '.mp3')):\n",
    "                continue\n",
    "\n",
    "            file_path = os.path.join(class_dir, file_name)\n",
    "            mfccs = extract_features(file_path)\n",
    "\n",
    "            if mfccs is not None:\n",
    "                features.append(mfccs)\n",
    "                labels.append(label_idx)\n",
    "\n",
    "    # Konversi ke numpy array dengan pengecekan\n",
    "    if not features:\n",
    "        raise ValueError(\"Tidak ada file audio yang berhasil diproses!\")\n",
    "\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return features, labels, label_dict\n",
    "\n",
    "# Bangun model CNN\n",
    "def build_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                 loss='sparse_categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    # Path dataset\n",
    "    dataset_dir = \"dataset_suara\"\n",
    "\n",
    "    try:\n",
    "        # Muat dataset\n",
    "        features, labels, label_dict = load_dataset(dataset_dir)\n",
    "        print(f\"Berhasil memuat {len(features)} sampel audio\")\n",
    "\n",
    "        # Reshape untuk CNN\n",
    "        X = features[..., np.newaxis]  # Tambah dimensi channel\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Latih model\n",
    "        model = build_model(X_train.shape[1:], len(label_dict))\n",
    "        history = model.fit(X_train, y_train,\n",
    "                          epochs=50,\n",
    "                          batch_size=32,\n",
    "                          validation_data=(X_test, y_test))\n",
    "\n",
    "        # Simpan model\n",
    "        model_path = \"dataset_suara/sound_model.h5\"\n",
    "        model.save(model_path)\n",
    "        np.save(\"dataset_suara/label_dict.npy\", label_dict)\n",
    "        print(f\"✅ Model disimpan di {model_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error utama: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dVZkRJ2_0reL",
   "metadata": {
    "id": "dVZkRJ2_0reL"
   },
   "source": [
    "predict sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sME3ixsHiXFd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55645,
     "status": "ok",
     "timestamp": 1746036938403,
     "user": {
      "displayName": "john alpha",
      "userId": "11702152668833067099"
     },
     "user_tz": -420
    },
    "id": "sME3ixsHiXFd",
    "outputId": "10ef7f0d-e7a5-4b12-8002-988c4d3ebc64"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model berhasil dimuat!\n",
      " * Aplikasi berjalan di: https://ad78-2400-9800-584-e796-5847-2013-f412-59d1.ngrok-free.app\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:127.0.0.1 - - [24/May/2025 14:29:48] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [24/May/2025 14:29:50] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [24/May/2025 14:29:58] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [24/May/2025 14:30:57] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [24/May/2025 14:37:08] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [24/May/2025 14:37:30] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [24/May/2025 14:37:42] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [24/May/2025 14:38:44] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [24/May/2025 14:42:40] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [24/May/2025 14:45:31] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [24/May/2025 14:45:53] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [24/May/2025 14:46:08] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [24/May/2025 14:46:30] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [24/May/2025 14:47:27] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [24/May/2025 14:47:44] \"POST / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import base64\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import tensorflow as tf\n",
    "\n",
    "from flask import Flask, request, render_template\n",
    "from werkzeug.utils import secure_filename\n",
    "\n",
    "from pyngrok import ngrok\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('token.env')  # Load dari file .env\n",
    "ngrok.set_auth_token(os.getenv(\"NGROK_AUTHTOKEN\"))\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Path konfigurasi\n",
    "model_path = \"dataset_suara/sound_model.h5\"\n",
    "label_dict_path = \"dataset_suara/label_dict.npy\"\n",
    "image_dir = \"GambarHasil\"\n",
    "\n",
    "UPLOAD_FOLDER = 'uploads'\n",
    "ALLOWED_EXTENSIONS = {'wav', 'mp3', 'ogg'}\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB\n",
    "\n",
    "os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)\n",
    "\n",
    "# Load model & label\n",
    "try:\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    label_dict = np.load(label_dict_path, allow_pickle=True).item()\n",
    "    print(\"✅ Model berhasil dimuat!\")\n",
    "    HEWAN_DIKENALI = list(label_dict.values())\n",
    "\n",
    "    reference_images = {\n",
    "        'anjing': os.path.join(image_dir, 'anjing.jpg'),\n",
    "        'ayam': os.path.join(image_dir, 'ayam.jpg'),\n",
    "        'burung': os.path.join(image_dir, 'burung.jpg'),\n",
    "        'domba': os.path.join(image_dir, 'domba.jpg'),\n",
    "        'keledai': os.path.join(image_dir, 'keledai.jpg'),\n",
    "        'kodok': os.path.join(image_dir, 'kodok.jpg'),\n",
    "        'kucing': os.path.join(image_dir, 'kucing.jpg'),\n",
    "        'monkey': os.path.join(image_dir, 'monkey.jpg'),\n",
    "        'sapi': os.path.join(image_dir, 'sapi.jpg'),\n",
    "        'singa': os.path.join(image_dir, 'singa.jpg')\n",
    "    }\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Gagal memuat model: {e}\")\n",
    "    raise\n",
    "\n",
    "# Cek ekstensi file\n",
    "def allowed_file(filename):\n",
    "    return '.' in filename and \\\n",
    "           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
    "\n",
    "# Ekstraksi fitur\n",
    "def ekstrak_fitur(file_path, max_pad_len=500, n_mels=128, n_mfcc=40):\n",
    "    try:\n",
    "        audio, sr = librosa.load(file_path, sr=22050)\n",
    "        audio = librosa.util.normalize(audio)\n",
    "        mel = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=n_mels)\n",
    "        mfccs = librosa.feature.mfcc(S=librosa.power_to_db(mel), n_mfcc=n_mfcc)\n",
    "\n",
    "        if mfccs.shape[1] > max_pad_len:\n",
    "            mfccs = mfccs[:, :max_pad_len]\n",
    "        else:\n",
    "            pad_width = max_pad_len - mfccs.shape[1]\n",
    "            mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "\n",
    "        return mfccs, audio, sr\n",
    "    except Exception as e:\n",
    "        print(f\"Gagal memproses {file_path}: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Visualisasi hasil prediksi\n",
    "def buat_visualisasi(audio, sr, mfccs, prediksi, kelas_prediksi):\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    librosa.display.waveshow(audio, sr=sr, color='blue')\n",
    "    plt.title('Gelombang Suara')\n",
    "    plt.xlabel('Waktu (detik)')\n",
    "    plt.ylabel('Amplitudo')\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    librosa.display.specshow(mfccs, x_axis='time', cmap='coolwarm')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Koefisien MFCC')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    probabilitas = prediksi[0]\n",
    "    warna = ['green' if h == kelas_prediksi else 'gray' for h in HEWAN_DIKENALI]\n",
    "    bars = plt.barh(HEWAN_DIKENALI, probabilitas, color=warna)\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        plt.text(width + 0.01, bar.get_y() + bar.get_height() / 2,\n",
    "                 f'{width:.2%}', ha='left', va='center')\n",
    "\n",
    "    plt.title('Probabilitas Prediksi')\n",
    "    plt.xlim(0, 1)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    buf.seek(0)\n",
    "\n",
    "    return base64.b64encode(buf.getvalue()).decode('utf8')\n",
    "\n",
    "# Prediksi suara\n",
    "def prediksi_suara(file_path):\n",
    "    try:\n",
    "        mfccs, audio, sr = ekstrak_fitur(file_path)\n",
    "        if mfccs is None:\n",
    "            return None, \"Gagal memproses file audio\"\n",
    "\n",
    "        mfccs_input = mfccs[np.newaxis, ..., np.newaxis]\n",
    "        prediksi = model.predict(mfccs_input)\n",
    "        kelas_prediksi = label_dict[np.argmax(prediksi)]\n",
    "\n",
    "        plot_url = buat_visualisasi(audio, sr, mfccs, prediksi, kelas_prediksi)\n",
    "\n",
    "        detail_prob = {\n",
    "            label_dict[i]: f\"{prob*100:.2f}%\"\n",
    "            for i, prob in enumerate(prediksi[0])\n",
    "        }\n",
    "\n",
    "        gambar_ref = None\n",
    "        img_path = reference_images.get(kelas_prediksi.lower(), None)\n",
    "        if img_path and os.path.exists(img_path):\n",
    "            with open(img_path, \"rb\") as img_file:\n",
    "                gambar_ref = \"data:image/jpeg;base64,\" + base64.b64encode(img_file.read()).decode('utf-8')\n",
    "\n",
    "        return {\n",
    "            'hasil': kelas_prediksi,\n",
    "            'plot': plot_url,\n",
    "            'probabilitas': detail_prob,\n",
    "            'waktu': datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"),\n",
    "            'gambar_referensi': gambar_ref\n",
    "        }, None\n",
    "    except Exception as e:\n",
    "        return None, str(e)\n",
    "\n",
    "# ROUTE\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def index():\n",
    "    if request.method == 'POST':\n",
    "        if 'file' not in request.files or request.files['file'].filename == '':\n",
    "            return render_template(\"hasil.html\", error=\"Tidak ada file yang dipilih\", hewan_dikenali=HEWAN_DIKENALI)\n",
    "\n",
    "        file = request.files['file']\n",
    "        if file and allowed_file(file.filename):\n",
    "            filename = secure_filename(file.filename)\n",
    "            filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
    "            file.save(filepath)\n",
    "\n",
    "            hasil, error = prediksi_suara(filepath)\n",
    "            if error:\n",
    "                return render_template(\"hasil.html\", error=error, hewan_dikenali=HEWAN_DIKENALI)\n",
    "\n",
    "            return render_template(\"hasil.html\", hasil=hasil, hewan_dikenali=HEWAN_DIKENALI)\n",
    "        else:\n",
    "            return render_template(\"hasil.html\", error=\"Format file tidak didukung.\", hewan_dikenali=HEWAN_DIKENALI)\n",
    "\n",
    "    return render_template(\"hasil.html\", hewan_dikenali=HEWAN_DIKENALI)\n",
    "\n",
    "# Jalankan Flask\n",
    "if __name__ == '__main__':\n",
    "    public_url = ngrok.connect(5000).public_url\n",
    "    print(\" * Aplikasi berjalan di:\", public_url)\n",
    "    app.run()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
